"""
Test script for Phase 6: AI Chat Assistant
Tests conversational Q&A with analysis results.
"""

from pathlib import Path
import sys
import json

# Add project root to path
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from app.services.video_analysis import VideoAnalysisService
from app.services.chat_assistant import ChatAssistant, quick_chat
import os


# Sample analysis results for testing (simulated)
def get_sample_analysis_results():
    """Get or generate sample analysis results."""
    video_path = project_root / "sample_video.mp4"
    
    if not video_path.exists():
        print(f"‚ùå Sample video not found: {video_path}")
        print("Please ensure sample_video.mp4 exists")
        return None
    
    print(f"üìπ Analyzing sample video to get results...")
    print(f"   (This may take a minute...)\n")
    
    # Create service
    service = VideoAnalysisService(
        frame_sample_rate=30,
        confidence_threshold=0.5,
        enable_ai_insights=True
    )
    
    # Analyze
    results = service.analyze_video(
        video_path=video_path,
        save_detections=False
    )
    
    if results.get("status") != "completed":
        print(f"‚ùå Analysis failed: {results.get('error', 'Unknown error')}")
        return None
    
    print(f"‚úÖ Analysis complete!\n")
    return results


def test_conversation_flow(results: dict, api_key: str = None):
    """Test a full conversation flow."""
    print("=" * 80)
    print("Test 1: Full Conversation Flow")
    print("=" * 80)
    
    # Create assistant
    assistant = ChatAssistant(api_key=api_key)
    
    # Start conversation
    print("\nü§ñ Starting conversation...\n")
    welcome = assistant.start_conversation(results)
    print(f"Assistant: {welcome}\n")
    
    # Test conversation with multiple questions
    questions = [
        "Why do you recommend this number of nurses?",
        "What if we only have 1 nurse available?",
        "How can we reduce the bottlenecks?",
        "When are the peak congestion times?",
        "Where should we position our staff?",
        "Thanks for the help!"
    ]
    
    conversation_history = []
    
    for i, question in enumerate(questions, 1):
        print(f"üë§ User: {question}")
        
        # Add user message to history
        conversation_history.append({
            "role": "user",
            "content": question,
            "timestamp": "2024-01-15T10:00:00"
        })
        
        # Get response
        response_data = assistant.send_message(question, conversation_history)
        
        # Add assistant response to history
        conversation_history.append({
            "role": "assistant",
            "content": response_data["response"],
            "timestamp": response_data["timestamp"]
        })
        
        print(f"ü§ñ Assistant: {response_data['response']}\n")
        print(f"   (Generated by: {response_data['generated_by']})")
        print()
    
    # Get conversation summary
    summary = assistant.get_conversation_summary(conversation_history)
    print(f"üìä Conversation Summary:")
    print(f"   - Total messages: {summary['message_count']}")
    print(f"   - User messages: {summary['user_messages']}")
    print(f"   - Topics discussed: {', '.join(summary['topics_discussed'])}")
    print()
    
    print("=" * 80)
    print()


def test_quick_chat(results: dict, api_key: str = None):
    """Test quick chat function."""
    print("=" * 80)
    print("Test 2: Quick Chat Function")
    print("=" * 80)
    
    questions = [
        "Explain the staffing recommendation",
        "What are the main bottleneck areas?",
        "How can we improve patient flow?"
    ]
    
    for question in questions:
        print(f"\nüë§ Question: {question}")
        response = quick_chat(question, results, api_key=api_key)
        print(f"ü§ñ Answer: {response}\n")
    
    print("=" * 80)
    print()


def test_what_if_scenarios(results: dict, api_key: str = None):
    """Test what-if scenario discussions."""
    print("=" * 80)
    print("Test 3: What-If Scenarios")
    print("=" * 80)
    
    assistant = ChatAssistant(api_key=api_key)
    assistant.start_conversation(results)
    
    scenarios = [
        "What if we increase staff by 50%?",
        "What if we can only afford 1 nurse during off-peak hours?",
        "What if we implement a triage system at the entrance?",
        "What would happen if we extended operating hours?"
    ]
    
    print("\nüéØ Testing scenario planning capabilities:\n")
    
    for scenario in scenarios:
        print(f"üë§ Scenario: {scenario}")
        response = assistant.send_message(scenario, [])
        print(f"ü§ñ Analysis: {response['response']}\n")
    
    print("=" * 80)
    print()


def test_context_retention(results: dict, api_key: str = None):
    """Test if assistant maintains context across messages."""
    print("=" * 80)
    print("Test 4: Context Retention")
    print("=" * 80)
    
    assistant = ChatAssistant(api_key=api_key)
    assistant.start_conversation(results)
    
    # Ask follow-up questions that require context
    conversation = [
        ("What's the peak congestion time?", "Initial question"),
        ("Why is it so busy then?", "Follow-up (requires remembering peak time)"),
        ("How many staff should we have during that period?", "Second follow-up"),
        ("What if we can't meet that staffing level?", "Alternative scenario")
    ]
    
    print("\nüß† Testing context retention across multiple messages:\n")
    
    history = []
    for question, note in conversation:
        print(f"üë§ User: {question}")
        print(f"   [{note}]")
        
        response = assistant.send_message(question, history)
        print(f"ü§ñ Assistant: {response['response']}\n")
        
        # Update history
        history.append({"role": "user", "content": question, "timestamp": response["timestamp"]})
        history.append({"role": "assistant", "content": response["response"], "timestamp": response["timestamp"]})
    
    print("=" * 80)
    print()


def test_error_handling(results: dict, api_key: str = None):
    """Test error handling and edge cases."""
    print("=" * 80)
    print("Test 5: Error Handling")
    print("=" * 80)
    
    assistant = ChatAssistant(api_key=api_key)
    assistant.start_conversation(results)
    
    edge_cases = [
        "",  # Empty message
        "asdfghjkl",  # Nonsense
        "What's the weather?",  # Off-topic
        "ü§îüè•üë®‚Äç‚öïÔ∏è",  # Emojis only
    ]
    
    print("\nüõ°Ô∏è Testing edge cases and error handling:\n")
    
    for i, message in enumerate(edge_cases, 1):
        print(f"Test {i}: {repr(message)}")
        try:
            response = assistant.send_message(message or " ", [])
            print(f"‚úÖ Handled: {response['response'][:100]}...")
        except Exception as e:
            print(f"‚ùå Error: {e}")
        print()
    
    print("=" * 80)
    print()


def test_assistant_info(api_key: str = None):
    """Test assistant information and configuration."""
    print("=" * 80)
    print("Test 6: Assistant Configuration")
    print("=" * 80)
    
    assistant = ChatAssistant(api_key=api_key)
    info = assistant.get_assistant_info()
    
    print("\nüìã Assistant Configuration:")
    print(f"   - Model: {info['model_name']}")
    print(f"   - Temperature: {info['temperature']}")
    print(f"   - Max Tokens: {info['max_output_tokens']}")
    print(f"   - Gemini Available: {info['gemini_available']}")
    print(f"   - Model Initialized: {info['model_initialized']}")
    print(f"   - Mode: {info['mode']}")
    print(f"   - Chat Active: {info['chat_active']}")
    print()
    
    print("=" * 80)
    print()


def main():
    """Run all tests."""
    print("\n" + "=" * 80)
    print(" PHASE 6: AI CHAT ASSISTANT TEST SUITE")
    print("=" * 80 + "\n")
    
    # Check for API key
    api_key = os.getenv("GEMINI_API_KEY")
    
    if api_key:
        print("‚úÖ GEMINI_API_KEY found in environment")
        print(f"   Key: {api_key[:10]}...{api_key[-4:]}" if len(api_key) > 14 else "   Key: [REDACTED]")
        print("   Will test AI chat mode\n")
    else:
        print("‚ö†Ô∏è  GEMINI_API_KEY not found in environment")
        print("   Will test rule-based chat mode\n")
    
    print("-" * 80 + "\n")
    
    # Get analysis results
    print("üìä Preparing analysis results for chat context...\n")
    results = get_sample_analysis_results()
    
    if not results:
        print("\n‚ùå Cannot proceed without analysis results")
        return
    
    # Display analysis summary
    stats = results.get("statistics", {})
    insights = results.get("insights", {})
    print(f"Analysis Summary:")
    print(f"   - Average people: {stats.get('average_person_count', 0):.1f}")
    print(f"   - Peak count: {stats.get('max_person_count', 0)}")
    print(f"   - Crowd level: {insights.get('crowd_level', 'Unknown')}")
    print(f"   - Suggested nurses: {insights.get('suggested_nurses', 0)}")
    print()
    
    print("-" * 80 + "\n")
    
    # Run tests
    try:
        # Test 1: Full conversation flow
        test_conversation_flow(results, api_key)
        
        # Test 2: Quick chat
        test_quick_chat(results, api_key)
        
        # Test 3: What-if scenarios
        test_what_if_scenarios(results, api_key)
        
        # Test 4: Context retention
        test_context_retention(results, api_key)
        
        # Test 5: Error handling
        test_error_handling(results, api_key)
        
        # Test 6: Assistant info
        test_assistant_info(api_key)
        
        print("\n" + "=" * 80)
        print(" ALL TESTS COMPLETE ‚úÖ")
        print("=" * 80 + "\n")
        
        if not api_key:
            print("üí° TIP: Set GEMINI_API_KEY to test AI chat mode")
            print("   export GEMINI_API_KEY='your_api_key'")
            print()
    
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  Tests interrupted by user")
    except Exception as e:
        print(f"\n\n‚ùå Test error: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
